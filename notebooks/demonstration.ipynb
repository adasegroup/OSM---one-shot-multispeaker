{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2198756e",
   "metadata": {},
   "source": [
    "# One-Shot Learning Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d01046a",
   "metadata": {},
   "source": [
    "The Jupyter Notebook should be launched in the folder **notebooks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0853b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../src')\n",
    "from osms.common.multispeaker import MultispeakerManager\n",
    "import torch\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae633721",
   "metadata": {},
   "source": [
    "Create a 5-second .wav file with someone speaking English and put it into the folder **audio_samples**.\n",
    "Set the path to your .wav file in the attribute `SPEAKER_SPEECH_PATH` in `src/tts_modules/common/configs/main_config.yaml`.\n",
    "We suggest to use the app [Audio Recorder](https://apps.apple.com/us/app/audio-recorder-wav-m4a/id1454488895) to record the voice. Set the sample rate to 16HGz there.\n",
    "\n",
    "Create a .txt file with some sentences written in English and put it into the **texts** folder. Set the path to your .txt file in the attribute `INPUT_TEXTS_PATH` in `src/tts_modules/common/configs/main_config.yaml`.\n",
    "\n",
    "\n",
    "The examples are already present in these folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3905c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), 'osms/tts_modules/common/configs/main_config.yaml'), \"r\") as ymlfile:\n",
    "    main_config = yaml.load(ymlfile)\n",
    "    \n",
    "SPEAKER_SPEECH_PATH = \"../audio_samples\"\n",
    "if not os.path.exists(SPEAKER_SPEECH_PATH):\n",
    "    os.makedirs(SPEAKER_SPEECH_PATH)\n",
    "    \n",
    "INPUT_TEXTS_PATH = \"../texts\"\n",
    "if not os.path.exists(INPUT_TEXTS_PATH):\n",
    "    os.makedirs(INPUT_TEXTS_PATH)\n",
    "    \n",
    "OUTPUT_AUDIO_DIR = \"../result_speech\"\n",
    "if not os.path.exists(OUTPUT_AUDIO_DIR):\n",
    "    os.makedirs(OUTPUT_AUDIO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2cfa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579b2553",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters in dVecModel: 1.424M\n",
      "Loading DVecModel checkpoint from checkpoints/encoder.pt\n",
      "Trainable Parameters in Tacotron: 30.870M\n",
      "Loading Tacotron checkpoint from checkpoints/synthesizer/synthesizer.pt\n",
      "Trainable Parameters in WaveRNN: 4.481M\n",
      "Loading WaveRNN checkpoint from checkpoints/vocoder/vocoder.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "       5.21322577e-07, 7.94726051e-08, 0.00000000e+00])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multispeaker_manager = MultispeakerManager(main_configs=main_config)\n",
    "multispeaker_manager.inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fcb1a0",
   "metadata": {},
   "source": [
    "The results will be available in the folder `result_speech`. The name of the file will be **result.wav**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbbe68",
   "metadata": {},
   "source": [
    "The usability will be further improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.optim import Adam\n",
    "import yaml\n",
    "os.chdir('../src')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from osms.tts_modules.encoder.configs import get_default_encoder_config\n",
    "from osms.tts_modules.encoder.data.dataset import PreprocessLibriSpeechDataset, SpeakerEncoderDataLoader, SpeakerEncoderDataset\n",
    "from osms.tts_modules.encoder.data.wav_preprocessing import StandardAudioPreprocessor\n",
    "from osms.tts_modules.encoder.data.wav2mel import StandardWav2MelTransform\n",
    "from osms.tts_modules.encoder.models.dVecModel import DVecModel\n",
    "from osms.tts_modules.encoder.utils.Trainer import SpeakerEncoderTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osms.tts_modules.encoder.speaker_encoder_manager import SpeakerEncoderManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osms.common.configs import get_default_main_configs\n",
    "from osms.tts_modules.encoder.configs import get_default_encoder_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_config = get_default_main_configs()\n",
    "encoder_config = get_default_encoder_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prerocessor = StandardAudioPreprocessor(encoder_config)\n",
    "wav2mel = StandardWav2MelTransform(encoder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SpeakerEncoderDataset(encoder_config)\n",
    "dataloader = SpeakerEncoderDataLoader(encoder_config, dataset, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters in dVecModel: 1.424M\n"
     ]
    }
   ],
   "source": [
    "model = DVecModel(encoder_config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "speaker_encoder_manager = SpeakerEncoderManager(main_config, model, prerocessor, \n",
    "                                                wav2mel, dataloader, dataloader, optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training from scratch.\n",
      "Saving the model (step 2)\n"
     ]
    }
   ],
   "source": [
    "speaker_encoder_manager.train_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gleb/python_venvs/venv3/lib/python3.7/site-packages/ipykernel_launcher.py:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "config = get_default_encoder_config()\n",
    "\n",
    "with open(\"./osms/tts_modules/encoder/configs/AudioConfig.yaml\", \"r\") as ymlfile:\n",
    "    audio_config = yaml.load(ymlfile)\n",
    "    \n",
    "prerocessor = StandardAudioPreprocessor(audio_config)\n",
    "wav2mel = StandardWav2MelTransform(audio_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MEL_N_CHANNELS': 40,\n",
       " 'MEL_WINDOW_STEP': 10,\n",
       " 'MEL_WINDOW_LENGTH': 40,\n",
       " 'SAMPLING_RATE': 16000,\n",
       " 'PARTIAL_UTTERANCE_N_FRAMES': 160,\n",
       " 'inference_n_frames': 80,\n",
       " 'VAD_WINDOW_LENGTH': 30,\n",
       " 'VAD_MOVING_AVERAGE_WIDTH': 8,\n",
       " 'VAD_MAX_SILENCE_LENGTH': 6,\n",
       " 'AUDIO_NORM_TARGET_dBFS': -30}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prerocessor.audio_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPreprocessor = PreprocessLibriSpeechDataset(config,prerocessor,wav2mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/61'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/5639'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/6829'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/908'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/672'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/.DS_Store'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/8455'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/8463'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/1320'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/2300'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/6930'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/260'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/1995'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/3575'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/4507'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/5683'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/7127'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/1284'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/121'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/1089'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/4992'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/4970'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/7021'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/1580'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/1188'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/8230'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/5142'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/2961'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/4446'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/8224'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/237'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/4077'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/5105'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/7729'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/2094'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/7176'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/1221'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/2830'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/3729'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/8555'), PosixPath('/Users/gleb/Documents/LibriSpeech/test-clean/3570')]\n"
     ]
    }
   ],
   "source": [
    "DataPreprocessor.preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gleb/python_venvs/venv3/lib/python3.7/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open(\"./osms/tts_modules/encoder/configs/dVecModelConfig.yaml\", \"r\") as ymlfile:\n",
    "    model_config = yaml.load(ymlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters in dVecModel: 1.424M\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "564727c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd4bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
